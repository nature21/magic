{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T03:35:57.159748Z",
     "start_time": "2024-10-11T03:35:57.105671Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuyao/miniconda3/envs/magic/lib/python3.10/site-packages/diffusers/models/unet_2d_condition.py:20: FutureWarning: `UNet2DConditionOutput` is deprecated and will be removed in version 0.29. Importing `UNet2DConditionOutput` from `diffusers.models.unet_2d_condition` is deprecated and this will be removed in a future version. Please use `from diffusers.models.unets.unet_2d_condition import UNet2DConditionOutput`, instead.\n",
      "  deprecate(\"UNet2DConditionOutput\", \"0.29\", deprecation_message)\n",
      "/home/yuyao/miniconda3/envs/magic/lib/python3.10/site-packages/diffusers/models/unet_2d_condition.py:25: FutureWarning: `UNet2DConditionModel` is deprecated and will be removed in version 0.29. Importing `UNet2DConditionModel` from `diffusers.models.unet_2d_condition` is deprecated and this will be removed in a future version. Please use `from diffusers.models.unets.unet_2d_condition import UNet2DConditionModel`, instead.\n",
      "  deprecate(\"UNet2DConditionModel\", \"0.29\", deprecation_message)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from env.envs.hookScene import HookScene\n",
    "from env.envs.mugScene import MugScene\n",
    "from env.envs.spoonScene import SpoonScene\n",
    "from scripts.hooking import get_reference as get_hooking_reference\n",
    "from scripts.hanging import get_reference as get_hanging_reference\n",
    "from scripts.scooping import get_reference as get_scooping_reference\n",
    "from magic.match import match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "327a7d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = 'hooking'\n",
    "tool_name = 'scissors'\n",
    "mug_id = tool_name\n",
    "spoon_id = tool_name\n",
    "sd_dino = False\n",
    "dift = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea7cd0dc2d4e1b5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T03:35:18.429268Z",
     "start_time": "2024-10-11T03:35:18.406827Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-10-11 12:34:37.662] [svulkan2] [error] GLFW error: X11: The DISPLAY environment variable is missing\n",
      "[2024-10-11 12:34:37.662] [svulkan2] [warning] Continue without GLFW.\n",
      "Found object data: name        hook\n",
      "filename     NaN\n",
      "scale       0.05\n",
      "rotation     NaN\n",
      "height       NaN\n",
      "hook_pos     NaN\n",
      "hook_rpy     NaN\n",
      "Name: 0, dtype: object\n",
      "Using additional scale: 0.025\n",
      "PCD mean: [ 0.57458307 -0.54972685  0.20005789]\n",
      "PCD min: [ 0.53719955 -0.66278052  0.18719953]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using default contact and grasp center (379, 200) (439, 532)\n"
     ]
    }
   ],
   "source": [
    "if task_name == 'hooking':\n",
    "    reference_img, reference_depth_img, reference_camera, reference_contact_center, reference_grasp_center, reference_scene, reference_init_pose, reference_pose = get_hooking_reference()\n",
    "elif task_name == 'hanging':\n",
    "    reference_img, reference_depth_img, reference_camera, reference_contact_center, reference_scene = get_hanging_reference()\n",
    "    reference_grasp_center = None\n",
    "elif task_name == 'scooping':\n",
    "    plane_origin = np.array([0, -0.35, 0])\n",
    "    plane_normal = np.array([0, -1, 0])\n",
    "    (reference_img, reference_contact_center, reference_collide_center, reference_grasp_center,\n",
    "     reference_pixel_to_3d_fn, reference_init_pose, reference_pcd_o3d) = get_scooping_reference(\n",
    "        manual_center=False, plane_origin=plane_origin, plane_normal=plane_normal\n",
    "    )\n",
    "else:\n",
    "    raise ValueError('Invalid task name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f921859dd3ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T03:35:23.059830Z",
     "start_time": "2024-10-11T03:35:23.034425Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-10-11 12:34:39.910] [SAPIEN] [warning] A second engine will share the same internal structures with the first one. Arguments passed to constructor will be ignored.\n",
      "[2024-10-11 12:34:39.910] [svulkan2] [warning] A second renderer will share the same internal context with the first one. Arguments passed to constructor will be ignored.\n",
      "[2024-10-11 12:34:39.910] [SAPIEN] [warning] Setting renderer more than once should be avoided.\n",
      "Loading object from /home/yuyao/magic/utils/../assets/ig/processed_dataset/scissors/Diamond_Visions_Scissors_Red/Diamond_Visions_Scissors_Red_cm_vhacd.obj\n",
      "Found object data: name        scissors\n",
      "filename         NaN\n",
      "scale            2.0\n",
      "rotation     0,0,180\n",
      "height           NaN\n",
      "hook_pos         NaN\n",
      "hook_rpy         NaN\n",
      "Name: 24, dtype: object\n",
      "Using additional scale: 1.0\n",
      "Using additional rotation: [0.000000e+00 0.000000e+00 1.000000e+00 6.123234e-17]\n",
      "Original rotation: [0.0, 0.0, 0.0, 1.0]\n",
      "New rotation: [0.000000e+00 0.000000e+00 1.000000e+00 6.123234e-17]\n",
      "PCD mean: [ 0.55823929 -0.7819348   0.23338986]\n",
      "PCD min: [ 0.46074951 -0.9422995   0.21694306]\n",
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b37a8f2e80f74e80a82c85c56d8e428f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.safetensors:  15%|#5        | 524M/3.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if task_name == 'hooking':\n",
    "    target_scene = HookScene(\n",
    "        tool_name,\n",
    "        'box',\n",
    "    )\n",
    "\n",
    "    target_scene.hide_env_visual()\n",
    "    target_img, target_depth_img, target_camera = target_scene.get_picture(\n",
    "        direction='+z',\n",
    "        additional_translation=np.array([0.6, -0.6, 0.2-0.375*1.414]),\n",
    "        debug_viewer=False,\n",
    "        get_depth=True\n",
    "    )\n",
    "    target_scene.unhide_env_visual()\n",
    "elif task_name == 'hanging':\n",
    "    target_scene = MugScene(\n",
    "        mug_id,\n",
    "        add_robot=True,\n",
    "        fps=480\n",
    "    )\n",
    "\n",
    "    target_scene.hide_env_visual()\n",
    "    target_img, target_depth_img, target_camera = target_scene.get_picture(direction='+x', debug_viewer=False, get_depth=True)\n",
    "    target_scene.unhide_env_visual()\n",
    "else:\n",
    "    plane_origin = np.array([0, -0.35, 0])\n",
    "    plane_normal = np.array([0, -1, 0])\n",
    "    target_scene = SpoonScene(\n",
    "        spoon_id,\n",
    "        fps=480,\n",
    "        add_robot=True,\n",
    "        radius=0.035\n",
    "    )\n",
    "\n",
    "    target_img, target_pixel_to_3d_fn = target_scene.get_slice(plane_origin, plane_normal)\n",
    "\n",
    "results, resized_imgs, downsampled_images = match(reference_img, target_img, reference_contact_center, reference_grasp_center, only_compute_dino_feature=True, sd_dino=sd_dino, dift=dift)\n",
    "results = results.permute(0, 2, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a60998b24cc5bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib \n",
    "matplotlib.use('TKAgg')\n",
    "%matplotlib inline\n",
    "\n",
    "fig, axes = plt.subplots(3, 5, figsize=(2 * resized_imgs[0].size[0] / 100, resized_imgs[0].size[1] / 100), dpi=100)\n",
    "for i in range(3):\n",
    "    for j in range(5):\n",
    "        axes[i][j].axis('off')\n",
    "\n",
    "axes[0][0].imshow(resized_imgs[0])\n",
    "source_point = reference_contact_center\n",
    "resized_source_point = np.array(source_point) / reference_img.size[1] * resized_imgs[0].size[0]\n",
    "axes[0][0].scatter(resized_source_point[0], resized_source_point[1], c='r', s=50)\n",
    "\n",
    "\n",
    "import cv2\n",
    "from tqdm import tqdm \n",
    "\n",
    "for rotation_index in tqdm(range(0, 12)):\n",
    "    downsampled_source_point = (np.array(source_point) / reference_img.size[1] * downsampled_images[0].size[1]).astype(int)\n",
    "    source_feature = results[0][downsampled_source_point[1], downsampled_source_point[0]]\n",
    "\n",
    "    target_feature = results[rotation_index+1]\n",
    "    heatmap = torch.sum(target_feature * source_feature, dim=-1).cpu().numpy()\n",
    "\n",
    "    # resize heatmap to target image size\n",
    "    heatmap = cv2.resize(heatmap, (resized_imgs[0].size[0], resized_imgs[0].size[1]), interpolation=cv2.INTER_LINEAR)\n",
    "    # gaussian filter\n",
    "    heatmap = cv2.GaussianBlur(heatmap, (25, 25), 0)\n",
    "    heatmap = (heatmap - np.min(heatmap)) / (np.max(heatmap) - np.min(heatmap))\n",
    "\n",
    "    # boost the heatmap where the feature is high for visualization\n",
    "    heatmap = np.power(heatmap, 10)\n",
    "\n",
    "    # get the coordinates of the maximum value in the heatmap\n",
    "    max_index = np.unravel_index(heatmap.argmax(), heatmap.shape)\n",
    "    target_point = max_index\n",
    "\n",
    "    # set the size of the canvas to be the same as the img\n",
    "    i = rotation_index // 4\n",
    "    j = rotation_index % 4 + 1\n",
    "    axes[i][j].imshow(resized_imgs[rotation_index+1])\n",
    "    axes[i][j].imshow(heatmap, alpha=0.8)\n",
    "    axes[i][j].scatter(target_point[1], target_point[0], c='r', s=50, marker='*')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
